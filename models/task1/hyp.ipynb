{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required libraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #linear algebra\n",
    "import pandas as pd # a data processing and CSV I/O library\n",
    "#from pandas_profiling import ProfileReport\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style='white', color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset(Exploring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = pd.read_csv('hypertension_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = hyp[np.isfinite(hyp).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score , classification_report, ConfusionMatrixDisplay,precision_score,recall_score, f1_score,roc_auc_score,roc_curve\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = hyp.drop('target',axis=1)\n",
    "y2 = hyp[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X2 , y2 , test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic_Regression\n",
      "Model performance for Training set (Hypertension)\n",
      "- Accuracy: 0.8571\n",
      "- F1 score: 0.855859\n",
      "- Precision: 0.860355\n",
      "- Recall: 0.857095\n",
      "----------------------------------\n",
      "Model performance for Test set (Hypertension)\n",
      "- Accuracy: 0.8557\n",
      "- Fl score: 0.8545\n",
      "- Precision: 0.8579\n",
      "- Recall: 0.8557\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision_Tree\n",
      "Model performance for Training set (Hypertension)\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.000000\n",
      "- Precision: 1.000000\n",
      "- Recall: 1.000000\n",
      "----------------------------------\n",
      "Model performance for Test set (Hypertension)\n",
      "- Accuracy: 1.0000\n",
      "- Fl score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Random_Forest\n",
      "Model performance for Training set (Hypertension)\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.000000\n",
      "- Precision: 1.000000\n",
      "- Recall: 1.000000\n",
      "----------------------------------\n",
      "Model performance for Test set (Hypertension)\n",
      "- Accuracy: 1.0000\n",
      "- Fl score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Nearest_Neighbors\n",
      "Model performance for Training set (Hypertension)\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 0.999952\n",
      "- Precision: 0.999952\n",
      "- Recall: 0.999952\n",
      "----------------------------------\n",
      "Model performance for Test set (Hypertension)\n",
      "- Accuracy: 0.9990\n",
      "- Fl score: 0.9990\n",
      "- Precision: 0.9990\n",
      "- Recall: 0.9990\n",
      "===================================\n",
      "\n",
      "\n",
      "Multinomial_Naive Bayes\n",
      "Model performance for Training set (Hypertension)\n",
      "- Accuracy: 0.7646\n",
      "- F1 score: 0.763923\n",
      "- Precision: 0.764175\n",
      "- Recall: 0.764607\n",
      "----------------------------------\n",
      "Model performance for Test set (Hypertension)\n",
      "- Accuracy: 0.7627\n",
      "- Fl score: 0.7620\n",
      "- Precision: 0.7620\n",
      "- Recall: 0.7627\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Logisitic_Regression\" :LogisticRegression(max_iter=20000),\n",
    "    \"Decision_Tree\" :DecisionTreeClassifier(),\n",
    "    \"Random_Forest\":RandomForestClassifier(),\n",
    "    \"K-Nearest_Neighbors\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Multinomial_Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train.values.ravel()) # Train Model\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred =  model.predict(X_test)\n",
    "\n",
    "  # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_pred) \n",
    "    model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') \n",
    "    model_test_precision = precision_score(y_test, y_test_pred , average='weighted') \n",
    "    model_test_recall  = recall_score(y_test, y_test_pred,average='weighted') \n",
    "\n",
    "  # Training set performance\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_pred) \n",
    "    model_train_f1 = f1_score(y_train, y_train_pred, average= 'weighted') \n",
    "    model_train_precision = precision_score(y_train, y_train_pred,average='weighted') \n",
    "    model_train_recall = recall_score(y_train, y_train_pred,average='weighted') \n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set (Hypertension)')\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print('- F1 score: {:4f}'.format(model_train_f1))\n",
    "    print('- Precision: {:4f}'.format(model_train_precision))\n",
    "    print('- Recall: {:4f}'.format(model_train_recall))\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print('Model performance for Test set (Hypertension)')\n",
    "    print('- Accuracy: {:.4f}'.format(model_test_accuracy) )\n",
    "    print('- Fl score: {:.4f}'.format(model_test_f1))\n",
    "    print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "    print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "models = {\n",
    "    \"Logisitic Regression\": LogisticRegression(max_iter=20000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train your model and then save it\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    # Save each model to a separate file\n",
    "    filename = f\"{model_name.replace(' ', '_').lower()}_model.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    pickle.dump(i, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "['C', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__sklearn_clone__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_build_request_for_signature', '_check_feature_names', '_check_n_features', '_estimator_type', '_get_default_requests', '_get_metadata_request', '_get_param_names', '_get_tags', '_more_tags', '_parameter_constraints', '_predict_proba_lr', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_validate_data', '_validate_params', 'class_weight', 'classes_', 'coef_', 'decision_function', 'densify', 'dual', 'feature_names_in_', 'fit', 'fit_intercept', 'get_metadata_routing', 'get_params', 'intercept_', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_features_in_', 'n_iter_', 'n_jobs', 'penalty', 'predict', 'predict_log_proba', 'predict_proba', 'random_state', 'score', 'set_fit_request', 'set_params', 'set_score_request', 'solver', 'sparsify', 'tol', 'verbose', 'warm_start']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "loaded_object = pickle.load(open(r\"logisitic_regression_model.pkl\", 'rb'))\n",
    "\n",
    "# Print the type and structure of the loaded object\n",
    "print(type(loaded_object))\n",
    "print(dir(loaded_object))  # List attributes and methods of the object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # Save the trained model using pickle\n",
    "    with open(f\"{list(models.keys())[i]}.pkl\", 'wb') as f:\n",
    "        pickle.dump(models, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "16840  45.0  0.0   0       125   304    0        0      162      1      0.0   \n",
      "1975   37.0  0.0   0       112   230    0        1      160      0      0.0   \n",
      "11521  73.0  0.0   2       152   212    0        0      150      0      0.8   \n",
      "22712  83.0  0.0   0       128   263    0        1      105      1      0.2   \n",
      "2764   76.0  1.0   1       136   319    1        0      152      0      0.0   \n",
      "...     ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "8778   64.0  1.0   1       122   192    0        1      174      0      0.0   \n",
      "6077   61.0  0.0   2       110   265    1        0      130      0      0.0   \n",
      "25858  73.0  1.0   0       160   228    0        0      138      0      2.3   \n",
      "12351  37.0  0.0   2       130   180    0        1      150      0      0.0   \n",
      "25977  75.0  1.0   2       155   269    0        1      148      0      0.8   \n",
      "\n",
      "       slope  ca  thal  \n",
      "16840      2   3     2  \n",
      "1975       2   1     2  \n",
      "11521      1   0     3  \n",
      "22712      1   1     3  \n",
      "2764       2   2     2  \n",
      "...      ...  ..   ...  \n",
      "8778       2   0     2  \n",
      "6077       2   1     2  \n",
      "25858      2   0     1  \n",
      "12351      2   0     2  \n",
      "25977      2   0     2  \n",
      "\n",
      "[5212 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Define the paths to your models using raw string literals (r\"...\")\n",
    "task1_model1_path = r\"logisitic_regression_model.pkl\"\n",
    "task1_model2_path = r\"decision_tree_model.pkl\"\n",
    "task2_model1_path = r\"random_forest_model.pkl\"\n",
    "task2_model2_path = r\"k-nearest_neighbors_model.pkl\"\n",
    "\n",
    "# Load models using pickle.load\n",
    "model_task1_1 = pickle.load(open(task1_model1_path, 'rb'))\n",
    "model_task1_2 = pickle.load(open(task1_model2_path, 'rb'))\n",
    "model_task2_1 = pickle.load(open(task2_model1_path, 'rb'))\n",
    "model_task2_2 = pickle.load(open(task2_model2_path, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "prediction_task1_1 = model_task1_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_task1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model does not have 'predict' attribute.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "\n",
    "# Load a model using pickle.load\n",
    "model = pickle.load(open(r\"Logisitic_Regression.pkl\", 'rb'))\n",
    "\n",
    "# Check if the model has the 'predict' attribute\n",
    "if hasattr(model, 'predict'):\n",
    "    print(\"Model has 'predict' attribute.\")\n",
    "else:\n",
    "    print(\"Model does not have 'predict' attribute.\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "16840  45.0  0.0   0       125   304    0        0      162      1      0.0   \n",
      "1975   37.0  0.0   0       112   230    0        1      160      0      0.0   \n",
      "11521  73.0  0.0   2       152   212    0        0      150      0      0.8   \n",
      "22712  83.0  0.0   0       128   263    0        1      105      1      0.2   \n",
      "2764   76.0  1.0   1       136   319    1        0      152      0      0.0   \n",
      "...     ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
      "8778   64.0  1.0   1       122   192    0        1      174      0      0.0   \n",
      "6077   61.0  0.0   2       110   265    1        0      130      0      0.0   \n",
      "25858  73.0  1.0   0       160   228    0        0      138      0      2.3   \n",
      "12351  37.0  0.0   2       130   180    0        1      150      0      0.0   \n",
      "25977  75.0  1.0   2       155   269    0        1      148      0      0.8   \n",
      "\n",
      "       slope  ca  thal  \n",
      "16840      2   3     2  \n",
      "1975       2   1     2  \n",
      "11521      1   0     3  \n",
      "22712      1   1     3  \n",
      "2764       2   2     2  \n",
      "...      ...  ..   ...  \n",
      "8778       2   0     2  \n",
      "6077       2   1     2  \n",
      "25858      2   0     1  \n",
      "12351      2   0     2  \n",
      "25977      2   0     2  \n",
      "\n",
      "[5212 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
